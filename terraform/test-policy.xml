<policies>
  <inbound>
    <base />
    
    <!-- Rate Limiting -->
    <rate-limit-by-key 
      calls="100" 
      renewal-period="60" 
      counter-key="@(context.Subscription?.Key ?? &quot;anonymous&quot;)" />
    
    <!-- Token Limit (approximate based on request size) -->
    <quota-by-key 
      calls="1000000" 
      bandwidth="40000" 
      renewal-period="60"
      counter-key="@(context.Subscription?.Key ?? &quot;anonymous&quot;)" />
    
    <!-- Managed Identity Authentication -->
    <authentication-managed-identity 
      resource="https://cognitiveservices.azure.com" 
      client-id="test-client-id"
      output-token-variable-name="managed-id-access-token" />
    
    <set-header name="Authorization" exists-action="override">
      <value>@("Bearer " + (string)context.Variables["managed-id-access-token"])</value>
    </set-header>
    
    <!-- Remove api-key header (we use managed identity) -->
    <set-header name="api-key" exists-action="delete" />
    
    <!-- Round-robin load balancing between backends -->
    <set-variable name="backendIndex" value="@(new Random().Next(0, 2))" />
    <choose>
      <when condition="@((int)context.Variables[&quot;backendIndex&quot;] == 0)">
        <set-backend-service backend-id="openai-backend-primary" />
        <set-variable name="selectedBackend" value="primary" />
      </when>
      <otherwise>
        <set-backend-service backend-id="openai-backend-secondary" />
        <set-variable name="selectedBackend" value="secondary" />
      </otherwise>
    </choose>
    
    <!-- Note: Cache policies removed - require external cache configuration -->
  </inbound>
  
  <backend>
    <!-- Retry on 429/5xx errors with failover to other backend -->
    <retry condition="@(context.Response.StatusCode == 429 || context.Response.StatusCode >= 500)" count="3" interval="1" first-fast-retry="true">
      <choose>
        <when condition="@((string)context.Variables[&quot;selectedBackend&quot;] == &quot;primary&quot;)">
          <set-backend-service backend-id="openai-backend-secondary" />
          <set-variable name="selectedBackend" value="secondary" />
        </when>
        <otherwise>
          <set-backend-service backend-id="openai-backend-primary" />
          <set-variable name="selectedBackend" value="primary" />
        </otherwise>
      </choose>
      <forward-request buffer-request-body="true" />
    </retry>
  </backend>
  
  <outbound>
    <base />
    
    <!-- Add custom headers for observability -->
    <set-header name="X-LLM-Gateway-Backend" exists-action="override">
      <value>@((string)context.Variables.GetValueOrDefault("selectedBackend", "unknown"))</value>
    </set-header>
  </outbound>
  
  <on-error>
    <base />
    
    <!-- Log errors to Application Insights -->
    <trace source="LLM-Gateway-Error" severity="error">
      <message>@(context.LastError.Message)</message>
      <metadata name="Error Source" value="@(context.LastError.Source)" />
      <metadata name="Error Reason" value="@(context.LastError.Reason)" />
    </trace>
    
    <!-- Return friendly error response -->
    <return-response>
      <set-status code="@(context.Response.StatusCode)" reason="@(context.Response.StatusReason)" />
      <set-header name="Content-Type" exists-action="override">
        <value>application/json</value>
      </set-header>
      <set-body>@{
        return new JObject(
          new JProperty("error", new JObject(
            new JProperty("code", context.Response.StatusCode.ToString()),
            new JProperty("message", context.LastError?.Message ?? "An error occurred"),
            new JProperty("request_id", context.RequestId.ToString())
          ))
        ).ToString();
      }</set-body>
    </return-response>
  </on-error>
</policies>

